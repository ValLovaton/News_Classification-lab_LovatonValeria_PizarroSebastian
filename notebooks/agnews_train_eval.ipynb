{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AG News Classification ‚Äî Comparaci√≥n de Transformers\n",
    "Este cuaderno cumple la r√∫brica de la **Task 2**:\n",
    "- Carga y particiona el dataset AG News (70/15/15)\n",
    "- Entrena RoBERTa, DeBERTa y ModernBERT\n",
    "- Calcula F1-scores y genera comparaci√≥n visual\n",
    "- Opcional bonus (usa `rpp_classified.json` para alinear con LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 0. Dependencias ===\n",
    "!pip -q install datasets transformers torch scikit-learn matplotlib seaborn\n",
    "import pandas as pd, numpy as np, torch, matplotlib.pyplot as plt, seaborn as sns\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. Dataset AG News ===\n",
    "dataset = load_dataset('ag_news')\n",
    "train_val = dataset['train'].train_test_split(test_size=0.3, seed=42)\n",
    "train = train_val['train']\n",
    "val_test = train_val['test'].train_test_split(test_size=0.5, seed=42)\n",
    "val, test = val_test['train'], val_test['test']\n",
    "print(train.shape, val.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. Tokenizaci√≥n ===\n",
    "def tokenize(batch, tokenizer):\n",
    "    return tokenizer(batch['text'], padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "model_names = [\n",
    "    'roberta-base',\n",
    "    'microsoft/deberta-base',\n",
    "    'jinaai/jina-bert-v2-base-es'  # ModernBERT (multiling√ºe)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3. Entrenamiento y evaluaci√≥n ===\n",
    "f1_scores = {}\n",
    "for model_name in model_names:\n",
    "    print(f'\\nüöÄ Entrenando {model_name}...')\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenized_train = train.map(lambda x: tokenize(x, tokenizer), batched=True)\n",
    "    tokenized_val = val.map(lambda x: tokenize(x, tokenizer), batched=True)\n",
    "    tokenized_train.set_format('torch', columns=['input_ids','attention_mask','label'])\n",
    "    tokenized_val.set_format('torch', columns=['input_ids','attention_mask','label'])\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4)\n",
    "    args = TrainingArguments(output_dir=f'outputs/{model_name}',\n",
    "                             evaluation_strategy='epoch',\n",
    "                             save_strategy='epoch',\n",
    "                             learning_rate=2e-5, per_device_train_batch_size=8,\n",
    "                             per_device_eval_batch_size=8, num_train_epochs=1,\n",
    "                             weight_decay=0.01, logging_dir='logs', logging_steps=100)\n",
    "\n",
    "    trainer = Trainer(model=model, args=args, train_dataset=tokenized_train,\n",
    "                      eval_dataset=tokenized_val, tokenizer=tokenizer)\n",
    "    trainer.train()\n",
    "\n",
    "    preds = trainer.predict(tokenized_val)\n",
    "    y_true = preds.label_ids\n",
    "    y_pred = preds.predictions.argmax(-1)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    f1_scores[model_name] = f1\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "print('\\nüìä F1-scores obtenidos:', f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4. Visualizaci√≥n ===\n",
    "sns.barplot(x=list(f1_scores.keys()), y=list(f1_scores.values()))\n",
    "plt.title('Comparaci√≥n de F1-score (validaci√≥n)')\n",
    "plt.ylabel('F1-macro')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß© Bonus (comparaci√≥n con LLM)\n",
    "Puedes cargar `data/rpp_classified.json` y comparar las predicciones de los tres modelos sobre las 50 noticias con las etiquetas LLM para calcular un nuevo F1-score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": { "display_name": "Python 3", "language": "python", "name": "python3" },
  "language_info": { "name": "python", "version": "3.10" }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

